{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8cKQMfgmngM"
      },
      "outputs": [],
      "source": [
        "#Import PyCBC\n",
        "import sys\n",
        "!{sys.executable} -m pip install pycbc ligo-common --no-cache-dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6KOQ8pfCxON"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "from scipy.interpolate import Akima1DInterpolator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from pycbc.waveform import get_td_waveform\n",
        "from pycbc.detector import Detector\n",
        "\n",
        "#Initial Conditions\n",
        "num_samples = 1000\n",
        "num_points = 3000\n",
        "noise_level = 0.3   #30% noise relative to signal peak\n",
        "\n",
        "\n",
        "#Generating Clean Waveforms\n",
        "def make_waveform(total_mass, effective_distance=100, num_points=3000):\n",
        "    mass1 = total_mass / 2\n",
        "    mass2 = total_mass / 2\n",
        "    apx = \"IMRPhenomD\"\n",
        "\n",
        "    #Generate the waveform\n",
        "    hp, hc = get_td_waveform(approximant=apx,\n",
        "                            mass1=mass1, mass2=mass2,\n",
        "                            spin1z=0.9, spin2z=0.9,\n",
        "                            distance=effective_distance,\n",
        "                            inclination=0, coa_phase=2.45,\n",
        "                            delta_t=1.0/4096, f_lower=40)\n",
        "\n",
        "    #Detector Projections (H1)\n",
        "    det_h1 = Detector('H1')\n",
        "    end_time, dec, ra, pol = 1292529720, 0.65, 4.67, 2.34\n",
        "    hp.start_time += end_time\n",
        "    hc.start_time += end_time\n",
        "\n",
        "    signal_h1 = det_h1.project_wave(hp, hc, ra, dec, pol)\n",
        "\n",
        "    time = signal_h1.sample_times.numpy()\n",
        "    signal = signal_h1.numpy()\n",
        "\n",
        "    #Masking near-zero points to focus on the \"Chirp\"\n",
        "    mask = np.abs(np.diff(signal, prepend=0)) > (0.0001 * np.max(np.abs(signal)))\n",
        "    time, signal = time[mask], signal[mask]\n",
        "\n",
        "    if len(time) < 10: # Safety check\n",
        "        return None, None\n",
        "\n",
        "    #Normalizing Time to [0, 1]\n",
        "    time = (time - time[0]) / (time[-1] - time[0])\n",
        "\n",
        "    #Interpolation to fixed length\n",
        "    interpolator = Akima1DInterpolator(time, signal)\n",
        "    sample_points = np.linspace(0, 1, num_points)\n",
        "    interpolated_signal = interpolator(sample_points)\n",
        "\n",
        "    #Final cleanup: Ensure no NaNs from interpolation\n",
        "    interpolated_signal = np.nan_to_num(interpolated_signal)\n",
        "\n",
        "    return sample_points, interpolated_signal\n",
        "\n",
        "#Generating Data\n",
        "print(f\"Generating {num_samples} noisy waveforms...\")\n",
        "masses = np.linspace(50, 600, num_samples)\n",
        "X_data = []\n",
        "y_data = []\n",
        "signals = []\n",
        "valid_masses = []\n",
        "\n",
        "for m in masses:\n",
        "    t, s = make_waveform(m, num_points=num_points)\n",
        "    if s is not None:\n",
        "        signals.append(s)\n",
        "        valid_masses.append(m)\n",
        "\n",
        "X = np.array(signals)\n",
        "y = np.array(valid_masses)\n",
        "\n",
        "#Expanding dims for CNN: (Samples, Time, Channels)\n",
        "X = X[..., np.newaxis]\n",
        "\n",
        "#Normalize X (Strain) to [-1, 1]\n",
        "X = X / np.max(np.abs(X), axis=1, keepdims=True)\n",
        "\n",
        "#Normalize y (Masses) to [0, 1] for better convergence\n",
        "y_min, y_max = y.min(), y.max()\n",
        "y_scaled = (y - y_min) / (y_max - y_min)\n",
        "\n",
        "#Generating Waveforms with Gaussian Noise\n",
        "def make_noisy_waveform(total_mass, noise_scale=0.2, num_points=3000):\n",
        "    t, clean_signal = make_waveform(total_mass, num_points=num_points)\n",
        "\n",
        "    if clean_signal is None:\n",
        "        return None, None\n",
        "\n",
        "    #Normalizing clean signal\n",
        "    max_amp = np.max(np.abs(clean_signal))\n",
        "    if max_amp == 0: return None, None\n",
        "    clean_signal = clean_signal / max_amp\n",
        "\n",
        "    #Generating Gaussian Noise\n",
        "    noise = np.random.normal(0, noise_scale, num_points)\n",
        "\n",
        "    #Combining Gaussian Noise and Normalized Noise\n",
        "    noisy_signal = clean_signal + noise\n",
        "\n",
        "    return t, noisy_signal\n",
        "\n",
        "for m in masses:\n",
        "    _, s = make_noisy_waveform(m, noise_scale=noise_level, num_points=num_points)\n",
        "    if s is not None:\n",
        "        X_data.append(s)\n",
        "        y_data.append(m)\n",
        "\n",
        "X = np.array(X_data)[..., np.newaxis] # Shape: (Samples, 3000, 1)\n",
        "\n",
        "#Log-transforming the target (Total Mass)\n",
        "y_log = np.log10(y_data)\n",
        "\n",
        "#Splitting 15% of Training Data for Test Data\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X, y_log, test_size=0.15, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "#Model\n",
        "model = Sequential([\n",
        "    Input(shape=(num_points, 1)),\n",
        "    Conv1D(32, 16, activation=\"relu\"),\n",
        "    MaxPooling1D(4),\n",
        "    Conv1D(64, 8, activation=\"relu\"),\n",
        "    MaxPooling1D(4),\n",
        "    Conv1D(128, 4, activation=\"relu\"),\n",
        "    MaxPooling1D(4),\n",
        "    Flatten(),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dropout(0.2), # Prevents overfitting on noise patterns\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary();\n",
        "\n",
        "#Training\n",
        "#EarlyStopping monitors the 'val_loss' to prevent overfitting\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_val, y_train_val,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2, # Takes 20% of X_train_val for experimentation\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "#Visuals\n",
        "\n",
        "#Converting predictions back from Log10 to Solar Masses\n",
        "preds_log = model.predict(X).flatten()\n",
        "preds_mass = 10**preds_log\n",
        "true_mass = 10**y_log\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(true_mass, preds_mass, alpha=0.3, s=10, label=\"Predictions\")\n",
        "plt.plot([50, 600], [50, 600], color='red', linestyle='--', label=\"Ideal\")\n",
        "plt.title(f\"Mass Estimation with Noise Level: {noise_level}\")\n",
        "plt.xlabel(\"True Mass ($M_{\\odot}$)\")\n",
        "plt.ylabel(\"Predicted Mass ($M_{\\odot}$)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Test Data Trial\n",
        "print(\"\\n--- FINAL TEST SET RESULTS ---\")\n",
        "test_mse = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Mean Squared Error: {test_mse:.5f}\")\n",
        "\n",
        "#Converting back to Solar Masses for interpretation\n",
        "preds_test_log = model.predict(X_test).flatten()\n",
        "preds_mass2 = 10**preds_test_log\n",
        "true_mass2 = 10**y_test\n",
        "\n",
        "#Visualizing Results\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "#Training Data Vs. Validation Data\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss (Experimentation)')\n",
        "plt.title('Learning Curves')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE (Log Scale)')\n",
        "plt.legend()\n",
        "\n",
        "# Test Data Performance\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(true_mass2, preds_mass2, alpha=0.5, color='green')\n",
        "plt.plot([50, 600], [50, 600], 'r--', label='Perfect Prediction')\n",
        "plt.title('Accuracy on Final Test Set')\n",
        "plt.xlabel('Actual Mass ($M_{\\odot}$)')\n",
        "plt.ylabel('Predicted Mass ($M_{\\odot}$)')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Define 5 different masses to showcase variety (similar to your image)\n",
        "sample_masses = [80, 150, 250, 400, 550]\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'] # Standard palette\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "# Store data for the chart (using the last mass in the loop)\n",
        "final_chart_df = None\n",
        "\n",
        "for i, m in enumerate(sample_masses):\n",
        "    # Use your existing make_noisy_waveform function\n",
        "    t, s_noisy = make_noisy_waveform(m, noise_scale=0.05, num_points=num_points)\n",
        "\n",
        "    # Plotting the line\n",
        "    plt.plot(t, s_noisy, label=f'Mass: {m}$M_\\odot$', color=colors[i], alpha=0.8)\n",
        "\n",
        "    # For the last wave, let's prepare the 10-point data chart\n",
        "    if i == len(sample_masses) - 1:\n",
        "        peak_idx = np.argmax(np.abs(s_noisy))\n",
        "        indices = np.arange(peak_idx - 10, peak_idx + 11)\n",
        "\n",
        "        # Highlight these points on the graph\n",
        "        plt.scatter(t[indices], s_noisy[indices], color='black', s=10, zorder=5, label='Chart Points')\n",
        "\n",
        "        final_chart_df = pd.DataFrame({\n",
        "            \"Time\": np.round(t[indices], 5),\n",
        "            \"Strain\": s_noisy[indices],\n",
        "            \"Type\": [\"Before\"]*10 + [\"PEAK/PRED\"] + [\"After\"]*10\n",
        "        })\n",
        "\n",
        "# Formatting the plot to match your reference\n",
        "plt.title(\"Strain vs. Time for 5 Gravitational Waves\", fontsize=14)\n",
        "plt.xlabel(\"Normalized Time\", fontsize=12)\n",
        "plt.ylabel(\"Strain\", fontsize=12)\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.show()\n",
        "\n",
        "# Display the requested data chart\n",
        "print(f\"\\n--- Data Points Chart (for {sample_masses[-1]} Solar Mass Wave) ---\")\n",
        "print(final_chart_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "eJnC53Dm43w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Convert log-scale predictions and true values back to Solar Masses\n",
        "# Ensure we are using the test set (unseen data)\n",
        "preds_test_log = model.predict(X_test).flatten()\n",
        "true_masses = 10**y_test\n",
        "predicted_masses = 10**preds_test_log\n",
        "\n",
        "# 2. Create the Comparison DataFrame\n",
        "comparison_df = pd.DataFrame({\n",
        "    'True Mass (M☉)': true_masses,\n",
        "    'Predicted Mass (M☉)': predicted_masses,\n",
        "    'Absolute Error (M☉)': np.abs(true_masses - predicted_masses),\n",
        "    'Percent Error (%)': np.abs((true_masses - predicted_masses) / true_masses) * 100\n",
        "})\n",
        "\n",
        "# 3. Sort by True Mass to see performance across the mass range\n",
        "comparison_df = comparison_df.sort_values(by='True Mass (M☉)')\n",
        "\n",
        "# 4. Display the first 20 results\n",
        "print(\"\\nTEST SET MASS COMPARISON TABLE\")\n",
        "print(comparison_df.head(20).to_string(index=False))\n",
        "\n",
        "# Optional: Save to CSV for external analysis\n",
        "# comparison_df.to_csv(\"mass_predictions.csv\", index=False)"
      ],
      "metadata": {
        "id": "DUnsifm745pc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}